geom_histogram(binwidth = 1)
summary(generated_data_points)
generate_data <- function(df, sampleSize) {
county <- c()
state <- c()
total <- c()
income <-c()
ratio <-c()
for(row in 1:nrow(df)){
for(i in 1:(sampleSize * df[row, "Households..Estimate..Less.than..10.000"]/100) ){
randomIncome <- runif(1,0,9999)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
for(i in 1:(sampleSize * df[row, "Households..Estimate...10.000.to..14.999"]/100) ){
randomIncome <- runif(1,10000,14999)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
for(i in 1:(sampleSize * df[row, "Households..Estimate...15.000.to..24.999"]/100) ){
randomIncome <- runif(1,15000,24999)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
for(i in 1:(sampleSize * df[row, "Households..Estimate...25.000.to..34.999"]/100) ){
randomIncome <- runif(1,25000,34999)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
for(i in 1:(sampleSize * df[row, "Households..Estimate...35.000.to..49.999"]/100) ){
randomIncome <- runif(1,35000,49999)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
for(i in 1:(sampleSize * df[row, "Households..Estimate...50.000.to..74.999"]/100) ){
randomIncome <- runif(1,50000,74999)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
for(i in 1:(sampleSize * df[row, "Households..Estimate...75.000.to..99.999"]/100) ){
randomIncome <- runif(1,75000,99999)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
for(i in 1:(sampleSize * df[row, "Households..Estimate...100.000.to..149.999"]/100) ){
randomIncome <- runif(1,100000,149999)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
for(i in 1:(sampleSize * df[row, "Households..Estimate...150.000.to..199.999"]/100) ){
randomIncome <- runif(1,150000,199999)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
for(i in 1:(sampleSize * df[row, "Households..Estimate...100.000.to..149.999"]/100) ){
randomIncome <- runif(1,200000,1000000)
county <- c(county,df[row,"Geographic.Area.Name"])
state <- c(state,df[row,"State"])
total <- c(total, df[row,"Total.Cost"])
income <- c(income,randomIncome )
ratio <- c(ratio, randomIncome/df[row,"Total.Cost"])
}
}
generated_df <- data.frame(county,state,total,income,ratio)
return(generated_df)
}
df_california <- final_dataset[final_dataset$State == "CA",]
generated_data_points <- generate_data(df_california, 100)
library(ggplot2)
ggplot(generated_data_points, aes(x = ratio)) +
geom_histogram(binwidth = 1)
summary(generated_data_points)
# We need to filter some of our own generated data points as it has become to large
Q1 <- 1.11258
Q3 <- 4.22250
Lower_Units <- Q1 - (1.5*IQR_Unit_Total)
Upper_Units <- Q3 + (1.5*IQR_Unit_Total)
lower <- generated_data_points[generated_data_points$ratio < Lower_Units,]
upper <- generated_data_points[generated_data_points$ratio > Upper_Units,]
print(nrow(lower) + nrow(upper))
IQR_ratio <- Q3 - Q1
Lower_Units <- Q1 - (1.5*IQR_ratio)
Upper_Units <- Q3 + (1.5*IQR_ratio)
lower <- generated_data_points[generated_data_points$ratio < Lower_ratio,]
upper <- generated_data_points[generated_data_points$ratio > Upper_ratio,]
Lower_ratio <- Q1 - (1.5*IQR_ratio)
Upper_ratio <- Q3 + (1.5*IQR_ratio)
lower <- generated_data_points[generated_data_points$ratio < Lower_ratio,]
upper <- generated_data_points[generated_data_points$ratio > Upper_ratio,]
print(nrow(lower) + nrow(upper))
clean_data <- df[generated_data_points$ratio >= Lower_ratio,]
clean_data <- df[generated_data_points$ratio <= Upper_ratio,]
ggplot(generated_data_points, aes(x = ratio, fill=county)) +
geom_histogram(binwidth = 1)
ggplot(clean_data, aes(x = ratio, fill=county)) +
geom_histogram(binwidth = 1)
View(clean_data)
clean_data <- generated_data_points[generated_data_points$ratio >= Lower_ratio,]
clean_data <- generated_data_points[generated_data_points$ratio <= Upper_ratio,]
ggplot(clean_data, aes(x = ratio, fill=county)) +
geom_histogram(binwidth = 1)
ggplot(clean_data, aes(x = ratio)) +
geom_histogram(binwidth = 1)
ggplot(clean_data, aes(x = ratio)) +
geom_histogram(binwidth = 0.5)
ggplot(clean_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5)
ggplot(clean_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5, bins=50) +
xlab("Ratio") +
ylab("Count") +
ggtitle("Distribution of Ratios, binsize = 0.5")+
df <- final_dataset[,-c(1:4, 18)]
ggplot(clean_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5, bins=50) +
xlab("Ratio") +
ylab("Count") +
ggtitle("Distribution of Ratios, binsize = 0.5")
ggplot(clean_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5) +
xlab("Ratio") +
ylab("Count") +
ggtitle("Distribution of Ratios, binsize = 0.5")
View(clean_data)
clean_data <- clean_data[,-c(2)]
Train <- createDataPartition(clean_data$ratio, p = 0.7, list = FALSE)
training <- df[ Train, ]
testing <- df[ - Train, ]
set.seed(123)
# build the  tree
fitM <- rpart(ratio~., method="anova", data=clean_data)
fitM <- rpart(ratio~., method="anova", data=clean_data)
#### Modeling ####
library(rpart)
fitM <- rpart(ratio~., method="anova", data=training)
View(training)
clean_generated_data <- generated_data_points[generated_data_points$ratio >= Lower_ratio,]
clean_generated_data <- generated_data_points[generated_data_points$ratio <= Upper_ratio,]
ggplot(clean_generated_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5) +
xlab("Ratio") +
ylab("Count") +
ggtitle("Distribution of Ratios, binsize = 0.5")
View(clean_generated_data)
clean_generated_data <- clean_data[,-c(2)]
Train <- createDataPartition(clean_generated_data$ratio, p = 0.7, list = FALSE)
training <- clean_generated_data[ Train, ]
testing <- clean_generated_data[ - Train, ]
set.seed(123)
fitM <- rpart(ratio~., method="anova", data=training)
printcp(fitM) # display the results
plotcp(fitM)
summary(fitM)
rsq.rpart(fitM) # visualize cross-validation results
# plot tree
plot(fitM, uniform=TRUE, main="Regression Tree for ratio ")
text(fitM, use.n=TRUE, all=TRUE, cex=.8)
# plot tree
plot(fitM, uniform=TRUE, main="Regression Tree for ratio ")
text(fitM, use.n=TRUE, all=TRUE, cex= 1)
# plot tree
plot(fitM, uniform=TRUE, main="Regression Tree for ratio ")
text(fitM, use.n=TRUE, all=TRUE, cex= 0.9)
# plot tree
plot(fitM, uniform=TRUE, main="Regression Tree for ratio ")
text(fitM, use.n=TRUE, all=TRUE, cex= 1.4)
# plot tree
plot(fitM, uniform=TRUE, main="Regression Tree for ratio ")
text(fitM, use.n=TRUE, all=TRUE, cex= 0.9)
# prune the tree
pfitM<- prune(fitM, cp=0.01160389) # from cptable??? adjust this to see the effect
# plot the pruned tree
plot(pfitM, uniform=TRUE, main="Pruned Regression Tree for Mileage")
text(pfitM, use.n=TRUE, all=TRUE, cex=.8)
post(pfitM, file = "ptree2.ps", title = "Pruned Regression Tree for Mileageâ€)
rpart.pred <- predict(rpart.model, testset[,-10], type = "class" )
rpart.pred <- predict(fitM, testing$ratio, type = "class" )
View(testing)
View(training)
library(ggplot2)
# We need to filter some of our own generated data points as it has become to large
Q1 <- 1.11258
Q3 <- 4.22250
IQR_ratio <- Q3 - Q1
Lower_ratio <- Q1 - (1.5*IQR_ratio)
Upper_ratio <- Q3 + (1.5*IQR_ratio)
lower <- generated_data_points[generated_data_points$ratio < Lower_ratio,]
upper <- generated_data_points[generated_data_points$ratio > Upper_ratio,]
print(nrow(lower) + nrow(upper))
clean_generated_data <- generated_data_points[generated_data_points$ratio >= Lower_ratio,]
clean_generated_data <- generated_data_points[generated_data_points$ratio <= Upper_ratio,]
ggplot(clean_generated_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5) +
xlab("Ratio") +
ylab("Count") +
ggtitle("Distribution of Ratios, binsize = 0.5")
View(clean_generated_data)
clean_generated_data <- clean_data[,-c(2)]
clean_generated_data <- clean_generated_data[,-c(2)]
lower <- generated_data_points[generated_data_points$ratio < Lower_ratio,]
upper <- generated_data_points[generated_data_points$ratio > Upper_ratio,]
print(nrow(lower) + nrow(upper))
clean_generated_data <- generated_data_points[generated_data_points$ratio >= Lower_ratio,]
clean_generated_data <- generated_data_points[generated_data_points$ratio <= Upper_ratio,]
View(clean_generated_data)
clean_generated_data <- clean_generated_data[,-c(2)]
Train <- createDataPartition(clean_generated_data$ratio, p = 0.7, list = FALSE)
training <- clean_generated_data[ Train, ]
testing <- clean_generated_data[ - Train, ]
View(testing)
model <- rpart(ratio~., method="anova", data=training)
printcp(fitM) # display the results
plotcp(model)
rsq.rpart(model) # visualize cross-validation results
# plot tree
plot(model, uniform=TRUE, main="Regression Tree for ratio ")
text(model, use.n=TRUE, all=TRUE, cex= 0.9)
rpart.pred <- predict(model, testing[,-c(4)], type = "class" )
pred <- predict(model, testing[,-c(4)] )
printcp(rpart.model)
printcp(model)
#Results of the cross validations
plotcp(rpart.model)
#Results of the cross validations
plotcp(model)
rsq.rpart(model)
print(rpart.model)
plot(rpart.pred)
plot(pred)
set.seed(123)
random_forest <- randomForest(ratio~.,
data = training,
ntree = 50,
importance =TRUE,
na.action=na.exclude)
random_forest
plot(random_forest)
pred_w_random <- predict(random_forest, testing)
tableCheck <- table(pred_w_random, testing$State)
#### Importance Frame ####
importance_frame <- measure_importance(random_forest)
plot_multi_way_importance(importance_frame, x_measure = "mse_increase", y_measure = "node_purity_increase", size_measure = "p_value", no_of_labels = 5)
View(cost_of_living_2015)
View(df_california)
random_forest <- randomForest(as.factor(county)~.,
data = training,
ntree = 50,
importance =TRUE,
na.action=na.exclude)
random_forest
View(training)
View(testing)
pred_w_random <- predict(random_forest, testing, type = "class")
tableCheck <- table(pred_w_random, testing$State)
tableCheck <- table(pred_w_random, testing$county)
tableCheck
# pred_w_random CA NY WA
# CA 72  0  3
# NY  0 69  2
# WA  0  0 30
sum(diag(tableCheck))/sum(tableCheck)
#0.972
plot(random_forest)
random_forest <- randomForest(total~.,
data = training,
ntree = 50,
importance =TRUE,
na.action=na.exclude)
random_forest
plot(random_forest)
clean_generated_data <- clean_generated_data[,-c(4)]
Train <- createDataPartition(clean_generated_data$ratio, p = 0.7, list = FALSE)
training <- clean_generated_data[ Train, ]
testing <- clean_generated_data[ - Train, ]
Train <- createDataPartition(clean_generated_data$total, p = 0.7, list = FALSE)
training <- clean_generated_data[ Train, ]
testing <- clean_generated_data[ - Train, ]
set.seed(123)
random_forest <- randomForest(total~.,
data = training,
ntree = 50,
importance =TRUE,
na.action=na.exclude)
random_forest
random_forest
plot(random_forest)
#### New York ####
df_NY <- final_dataset[final_dataset$State == "NY",]
generated_data_points <- generate_data(df_NY, 100)
ggplot(generated_data_points, aes(x = ratio)) +
geom_histogram(binwidth = 1)
ggplot(generated_data_points, aes(x = ratio)) +
geom_histogram(binwidth = 1)+
ggtitle("Distribution of Ratios")
ggplot(generated_data_points, aes(x = ratio)) +
geom_histogram(binwidth = 1)+
ggtitle("Distribution of Ratios for NY")
summary(generated_data_points)
# We need to filter some of our own generated data points as it has become to large
Q1 <- 1.32929
Q3 <- 5.13944
IQR_ratio <- Q3 - Q1
Lower_ratio <- Q1 - (1.5*IQR_ratio)
Upper_ratio <- Q3 + (1.5*IQR_ratio)
lower <- generated_data_points[generated_data_points$ratio < Lower_ratio,]
upper <- generated_data_points[generated_data_points$ratio > Upper_ratio,]
print(nrow(lower) + nrow(upper))
clean_generated_data <- generated_data_points[generated_data_points$ratio >= Lower_ratio,]
clean_generated_data <- generated_data_points[generated_data_points$ratio <= Upper_ratio,]
ggplot(clean_generated_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5) +
xlab("Ratio") +
ylab("Count") +
ggtitle("Distribution of Ratios, binsize = 0.5")
clean_generated_data <- clean_generated_data[,-c(2,5)]
Train <- createDataPartition(clean_generated_data$total, p = 0.7, list = FALSE)
training <- clean_generated_data[ Train, ]
testing <- clean_generated_data[ - Train, ]
set.seed(123)
random_forest <- randomForest(total~.,
data = training,
ntree = 50,
importance =TRUE,
na.action=na.exclude)
random_forest
plot(random_forest)
#### WA ####
df_WA <- final_dataset[final_dataset$State == "WA",]
generated_data_points <- generate_data(df_WA, 100)
ggplot(generated_data_points, aes(x = ratio)) +
geom_histogram(binwidth = 1)+
ggtitle("Distribution of Ratios for WA")
summary(generated_data_points)
# We need to filter some of our own generated data points as it has become to large
Q1 <- 1.47486
Q3 <- 5.16346
IQR_ratio <- Q3 - Q1
Lower_ratio <- Q1 - (1.5*IQR_ratio)
Upper_ratio <- Q3 + (1.5*IQR_ratio)
lower <- generated_data_points[generated_data_points$ratio < Lower_ratio,]
upper <- generated_data_points[generated_data_points$ratio > Upper_ratio,]
print(nrow(lower) + nrow(upper))
clean_generated_data <- generated_data_points[generated_data_points$ratio >= Lower_ratio,]
clean_generated_data <- generated_data_points[generated_data_points$ratio <= Upper_ratio,]
ggplot(clean_generated_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5) +
xlab("Ratio") +
ylab("Count") +
ggtitle("Distribution of Ratios Outliers Removed, binsize = 0.5")
clean_generated_data <- clean_generated_data[,-c(2,5)]
Train <- createDataPartition(clean_generated_data$total, p = 0.7, list = FALSE)
training <- clean_generated_data[ Train, ]
testing <- clean_generated_data[ - Train, ]
set.seed(123)
random_forest <- randomForest(total~.,
data = training,
ntree = 50,
importance =TRUE,
na.action=na.exclude)
random_forest
plot(random_forest)
df_california <- final_dataset[final_dataset$State == "CA",]
generated_data_points <- generate_data(df_california, 100)
importance_frame <- measure_importance(random_forest)
plot_multi_way_importance(importance_frame, x_measure = "accuracy_decrease", y_measure = "gini_decrease", size_measure = "p_value", no_of_labels = 5)
plot_multi_way_importance(importance_frame, x_measure = "mse_increase", y_measure = "node_purity_increase ", size_measure = "p_value", no_of_labels = 5)
importance_frame
plot_multi_way_importance(importance_frame, x_measure = "mse_increase", y_measure = "node_purity_increase ", size_measure = "p_value", no_of_labels = 5)
plot_multi_way_importance(importance_frame, x_measure = "mse_increase", y_measure = "node_purity_increase ", size_measure = "p_value")
library(randomForestExplainer)
plot_multi_way_importance(importance_frame, x_measure = "mse_increase", y_measure = "node_purity_increase ", size_measure = "p_value")
plot_multi_way_importance(importance_frame, x_measure = "mse_increase", y_measure = "node_purity_increase", size_measure = "p_value")
#### New York ####
df_NY <- final_dataset[final_dataset$State == "NY",]
generated_data_points <- generate_data(df_NY, 100)
ggplot(generated_data_points, aes(x = ratio)) +
geom_histogram(binwidth = 1)+
ggtitle("Distribution of Ratios for NY")
summary(generated_data_points)
# county             state               total           income             ratio
# Length:24154       Length:24154       Min.   :19904   Min.   :     2.8   Min.   : 0.00009
# Class :character   Class :character   1st Qu.:22744   1st Qu.: 33865.0   1st Qu.: 1.32929
# Mode  :character   Mode  :character   Median :24487   Median : 70530.5   Median : 2.74506
# Mean   :26355   Mean   :145335.8   Mean   : 5.60795
# 3rd Qu.:28695   3rd Qu.:135010.7   3rd Qu.: 5.13944
# Max.   :44547   Max.   :999890.9   Max.   :49.39495
# We need to filter some of our own generated data points as it has become to large
Q1 <- 1.32929
Q3 <- 5.13944
IQR_ratio <- Q3 - Q1
Lower_ratio <- Q1 - (1.5*IQR_ratio)
Upper_ratio <- Q3 + (1.5*IQR_ratio)
# Filtering out data using our IQR value (Fences method)
lower <- generated_data_points[generated_data_points$ratio < Lower_ratio,]
upper <- generated_data_points[generated_data_points$ratio > Upper_ratio,]
print(nrow(lower) + nrow(upper))
# Getting Rid of 3043 data entries
clean_generated_data <- generated_data_points[generated_data_points$ratio >= Lower_ratio,]
clean_generated_data <- generated_data_points[generated_data_points$ratio <= Upper_ratio,]
ggplot(clean_generated_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5) +
xlab("Ratio") +
ylab("Count") +
ggtitle("Distribution of Ratios, binsize = 0.5")
clean_generated_data <- clean_generated_data[,-c(2,5)]
#### Modeling ####
Train <- createDataPartition(clean_generated_data$total, p = 0.7, list = FALSE)
training <- clean_generated_data[ Train, ]
testing <- clean_generated_data[ - Train, ]
set.seed(123)
random_forest <- randomForest(total~.,
data = training,
ntree = 50,
importance =TRUE,
na.action=na.exclude)
random_forest
# Call:
#   randomForest(formula = total ~ ., data = training, ntree = 50,      importance = TRUE, na.action = na.exclude)
# Type of random forest: regression
# Number of trees: 50
# No. of variables tried at each split: 1
#
# Mean of squared residuals: 2791977
# % Var explained: 88.93
plot(random_forest)
importance_frame <- measure_importance(random_forest)
importance_frame
plot_multi_way_importance(importance_frame, x_measure = "mse_increase", y_measure = "node_purity_increase", size_measure = "p_value")
df_california <- final_dataset[final_dataset$State == "CA",]
generated_data_points <- generate_data(df_california, 100)
library(ggplot2)
ggplot(generated_data_points, aes(x = ratio)) +
geom_histogram(binwidth = 1)
summary(generated_data_points)
# county             state               total           income             ratio
# Length:24510       Length:24510       Min.   :21979   Min.   :     9.9   Min.   : 0.00041
# Class :character   Class :character   1st Qu.:27014   1st Qu.: 36277.2   1st Qu.: 1.11258
# Mode  :character   Mode  :character   Median :31307   Median : 73804.3   Median : 2.24521
# Mean   :34219   Mean   :152033.0   Mean   : 4.57500
# 3rd Qu.:38889   3rd Qu.:141867.0   3rd Qu.: 4.22250
# Max.   :65213   Max.   :999864.3   Max.   :42.88231
# We need to filter some of our own generated data points as it has become to large
Q1 <- 1.11258
Q3 <- 4.22250
IQR_ratio <- Q3 - Q1
Lower_ratio <- Q1 - (1.5*IQR_ratio)
Upper_ratio <- Q3 + (1.5*IQR_ratio)
# Filtering out data using our IQR value (Fences method)
lower <- generated_data_points[generated_data_points$ratio < Lower_ratio,]
upper <- generated_data_points[generated_data_points$ratio > Upper_ratio,]
print(nrow(lower) + nrow(upper))
# Getting Rid of 3188 data entries
clean_generated_data <- generated_data_points[generated_data_points$ratio >= Lower_ratio,]
clean_generated_data <- generated_data_points[generated_data_points$ratio <= Upper_ratio,]
ggplot(clean_generated_data, aes(x = ratio, fill = county)) +
geom_histogram(binwidth = 0.5) +
xlab("Ratio") +
ylab("Count") +
ggtitle("Distribution of Ratios, binsize = 0.5")
clean_generated_data <- clean_generated_data[,-c(2)]
clean_generated_data <- clean_generated_data[,-c(4)]
#### Modeling ####
library(rpart)
Train <- createDataPartition(clean_generated_data$total, p = 0.7, list = FALSE)
training <- clean_generated_data[ Train, ]
testing <- clean_generated_data[ - Train, ]
set.seed(123)
random_forest <- randomForest(total~.,
data = training,
ntree = 50,
importance =TRUE,
na.action=na.exclude)
random_forest
# Call:
#   randomForest(formula = total ~ ., data = training, ntree = 50,      importance = TRUE, na.action = na.exclude)
# Type of random forest: regression
# Number of trees: 50
# No. of variables tried at each split: 1
#
# Mean of squared residuals: 5506245
# % Var explained: 93.78
plot(random_forest)
importance_frame <- measure_importance(random_forest)
importance_frame
plot_multi_way_importance(importance_frame, x_measure = "mse_increase", y_measure = "node_purity_increase", size_measure = "p_value")
